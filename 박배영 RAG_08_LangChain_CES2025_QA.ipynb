{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/under71/assist/blob/main/%EB%B0%95%EB%B0%B0%EC%98%81%20RAG_08_LangChain_CES2025_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 벡터 DB 사용 RAG 구성"
      ],
      "metadata": {
        "id": "NelpC00Rk8-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 연관 라이브러리\n",
        "\n",
        "# #  The issue is with the update of httpx to 0.28. (proxies)\n",
        "!pip install httpx==0.27.2\n",
        "\n",
        "!pip install python-dotenv\n",
        "# !pip install faiss\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "# for CPU\n",
        "# !apt install libomp-dev\n",
        "# !pip install faiss\n",
        "\n",
        "# for GPU\n",
        "!pip install faiss-gpu\n"
      ],
      "metadata": {
        "id": "V6CJGxqdlGqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6629b6a-e298-4343-e55e-306f47148e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.11/dist-packages (0.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "\n",
        "# txt 경로\n",
        "#txt_url = \"https://raw.githubusercontent.com/under71/assist/refs/heads/main/ces2025_ko.txt\"\n",
        "#txt_url = \"https://raw.githubusercontent.com/under71/assist/refs/heads/main/ces2025_en.txt\"\n",
        "txt_url = \"https://raw.githubusercontent.com/under71/assist/refs/heads/main/ces2025_jp.txt\"\n",
        "txt_dir = \"./\"\n",
        "#txt_file =  'ces2025_ko.txt'\n",
        "#txt_file =  'ces2025_en.txt'\n",
        "txt_file =  'ces2025_jp.txt'\n",
        "txt_path = os.path.join(txt_dir, txt_file)\n",
        "urllib.request.urlretrieve(txt_url, txt_path)"
      ],
      "metadata": {
        "id": "PiuXrz40lLvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d57ac04-bbba-4e97-b256-6ebc6b25d71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./ces2025_jp.txt', <http.client.HTTPMessage at 0x7f5061c88c10>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ces2025_ko.txt\n",
        "!cat ces2025_jp.txt\n",
        "!cat ces2025_en.txt"
      ],
      "metadata": {
        "id": "wI_m4AXPoLp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238036a5-f7c8-4a70-bcc7-f298bc5bb4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "젠슨 황 엔비디아 창업자가 CES 2025 개막 기조연설을 했다. 현장은 설렘과 기대감, 호기심으로 가득 찼다. 자신감과 카리스마 넘치는 연설은 순식간에 청중을 빨아들였다. \r\n",
            "연설과 함께 필자는 CES 2025 혁신상 심사위원으로서 그의 기조연설에 나타난 핵심 주제를 분석해봤다.황의 기조연설은 AI와 컴퓨팅 혁신, 산업 AI와 디지털 트윈, 자율주행과 합성 데이터, 휴머노이드 로봇과 일반 로봇공학, AI 에이전트로 요약됐다.\r\n",
            "◇ AI와 컴퓨팅의 혁신, 새로운 미래 연다\r\n",
            "젠슨 황은 GPU가 현대 컴퓨팅의 패러다임 전환을 이끌고 있다고 진단했다. 기존의 CPU 중심 컴퓨팅에서 GPU 기반 가속 컴퓨팅으로 이동하며, AI가 컴퓨팅 인프라의 중심축으로 자리 잡고 있다는 분석이다.\r\n",
            "그는 엔비디아의 쿠다(CUDA)는 프로그래밍 가능한 GPU를 통해 복잡한 AI 알고리즘을 효율적으로 처리할 수 있도록 함으로써 다양한 AI 연구와 응용을 가능하게 했다고 설명했다.\r\n",
            "또한 AI가 텍스트, 이미지, 음성 등을 종합적으로 이해하고 생성할 수 있는 능력을 가지면서 AI가 새로운 차원으로 진화하고 있다.\r\n",
            "◇ AI와 디지털 트윈, 산업혁신 이끈다\r\n",
            "젠슨 황은 디지털 트윈(Digital Twin)이 AI와 물리적 세계를 연결해 산업혁신을 일이킬 것이라고 전망했다. \r\n",
            "그는 엔비디아의 옴니버스(Omniverse) 플랫폼이 물리적 환경을 디지털로 시뮬레이션해주고 코스모스(Cosmos)가 AI와 물리적 데이터를 결합해 시뮬레이션을 고도화하는 역할을 한다고 설명했다. 황은 이를 통해 제조, 물류, 에너지 산업에서 최적의 프로세스를 설계해 산업을 혁신할 수 있다고 단언했다.\r\n",
            "디지털 트윈은 모든 물리적 환경을 디지털로 재현하고 최적화할 수 있는 강력한 도구로 AI의 진화는 제조와 물류 산업의 미래를 변화시킬 전망이다.\r\n",
            "◇ AI 합성 데이터, 자율주행 안전시대 연다 \r\n",
            "젠슨 황은 자율주행 기술의 발전에서 합성 데이터의 중요성을 특히 강조했다. 자율주행차의 AI 모델은 합성 데이터를 통해 훈련되며, 이 데이터는 실제 데이터를 보완해 기술의 신뢰성을 높이는 역할을 한다. \r\n",
            "옴니버스와 코스모스를 통해 생성된 합성 데이터는 다양한 주행 시나리오를 시뮬레이션해 AI 모델의 정확성을 높여 차량의 안정성을 향상시킬 수 있다.\r\n",
            "◇ AI, 휴머노이드 공존시대 연다\r\n",
            "젠슨 황은 로봇공학이 AI와 결합하며 인간과 협력하는 새로운 시대를 열 것이라고 전망했다. 특히, 휴머노이드 로봇과 일반 로봇의 발전은 인간의 노동을 보완하고 새로운 가능성을 창출할 것으로 내다봤다.\r\n",
            "장차 휴머노이드 로봇은 인간의 동작을 모방해 다양한 산업 영역에서 활동하게 되며 방대한 합성 데이터와 현실 세계의 데이터를 로봇이 학습해 갈수록 복잡한 작업을 수행할 수 있게 된다.\r\n",
            "휴머노이드 로봇이 단순한 노동 대체를 넘어, 인간과의 협력을 통해 새로운 가치를 창출할 수 있는 도구가 된다. 이는 제조업과 서비스 산업의 변화를 촉진할 전망이다. \r\n",
            "◇ AI, 새로운 노동 계층을 창출하다\r\n",
            "젠슨 황은 AI가 새로운 노동 계층을 창출해 기존의 노동 시장을 재편할 것이라고 전망했다. 이는 단순히 인간의 일자리를 대체하는 것이 아니라, AI와 협력해 새로운 형태의 노동을 만들어내는 것을 의미한다.\r\n",
            "데이터 분석, 고객 서비스, 소프트웨어 개발 등에서 인간을 돕는 디지털 직원으로 역할을 하는 AI 기반 에이전트 세상이 열린다. 이로 인해 AI를 활용한 창의적 작업과 문제 해결 능력은 새로운 노동 시장의 핵심이 된다. 젠슨 황은 AI가 인간의 역량을 증폭시키며, 기술과 인간의 공존을 통해 더 나은 사회를 만들 것이라고 강조했다.\r\n",
            "젠슨 황은 기조연설을 통해 AI가 단순히 기술의 진보가 아니라, 사회와 산업의 구조를 근본적으로 변화시키는 혁신의 중심에 있음을 강조했다. AI와 인간이 함께 설계하는 미래의 가능성을 이야기한 것이다. 이제 우리는 AI가 열어갈 새로운 시대를 준비하며, 기술과 인간의 공존이 만들어낼 혁신을 CES 2025 슬로건대로 ‘탐구(DIVE IN)’하자.エヌビディア創業者のジェンセン・ファン氏がCES 2025の開幕基調講演を行いました。\n",
            "会場は期待感、興奮、好奇心で溢れていました。彼の自信とカリスマ性に満ちた講演は、瞬く間に観客を魅了しました。\n",
            "講演に加え、私はCES 2025イノベーションアワードの審査員として、彼の基調講演で示された主要テーマを分析しました。\n",
            "ファン氏の基調講演は、AIとコンピューティングの革新、産業AIとデジタルツイン、自動運転と合成データ、ヒューマノイドと一般ロボティクス、そしてAIエージェントに要約されます。\n",
            "\n",
            "AIとコンピューティングの革新、新たな未来を切り開く\n",
            "ジェンセン・ファン氏は、GPUが現代のコンピューティングにおけるパラダイムシフトを牽引していると述べました。\n",
            "彼は、従来のCPU中心のコンピューティングからGPUを基盤とする加速コンピューティングへの移行により、AIがコンピューティングインフラの中核として位置づけられていると説明しました。\n",
            "また、エヌビディアのCUDA（Compute Unified Device Architecture）はプログラム可能なGPUを通じて複雑なAIアルゴリズムを効率的に処理し、多様なAI研究や応用を可能にすると述べました。\n",
            "さらに、AIはテキスト、画像、音声を包括的に理解し生成する能力を持ち、新たな次元へと進化していると指摘しました。\n",
            "\n",
            "AIとデジタルツイン、産業革新を促進\n",
            "ジェンセン・ファン氏は、デジタルツインがAIと物理世界を結び付け、産業革新を促進すると予測しました。\n",
            "彼は、エヌビディアのOmniverseプラットフォームが物理的な環境をデジタルでシミュレーションし、CosmosがAIと物理データを統合してシミュレーションを高度化する役割を果たすと説明しました。\n",
            "これにより、製造、物流、エネルギー産業において最適なプロセスを設計し、産業を革新することができると断言しました。\n",
            "デジタルツインは、物理的環境をすべてデジタルで再現し最適化できる強力なツールであり、AIの進化により製造業と物流業の未来を変革すると見込まれています。\n",
            "\n",
            "AI合成データ、自動運転の安全時代を開く\n",
            "ジェンセン・ファン氏は、自動運転技術の進歩における合成データの重要性を特に強調しました。\n",
            "自動運転車のAIモデルは合成データによって訓練され、このデータが実データを補完し、技術の信頼性を向上させる役割を果たすと述べました。\n",
            "OmniverseとCosmosを通じて生成された合成データは、さまざまな走行シナリオをシミュレーションし、AIモデルの精度を向上させ、車両の安全性を高めることができます。\n",
            "\n",
            "AIとヒューマノイドの共存時代を開く\n",
            "ジェンセン・ファン氏は、ロボティクスがAIと結びつくことで、人間と協力する新しい時代を切り開くと予測しました。\n",
            "特に、ヒューマノイドロボットと一般ロボットの進化は、人間の労働を補完し、新たな可能性を創出すると見込まれます。\n",
            "将来的には、ヒューマノイドロボットが人間の動きを模倣し、さまざまな産業分野で活動するようになります。広範な合成データと現実世界のデータを学習することで、より複雑な作業を遂行できるようになるでしょう。\n",
            "ヒューマノイドロボットは単なる労働の代替を超え、人間との協力を通じて新たな価値を創出するツールとなります。これにより、製造業とサービス産業の変革が促進されると予測されます。\n",
            "\n",
            "AI、新しい労働階層を創出\n",
            "ジェンセン・ファン氏は、AIが新しい労働階層を創出し、既存の労働市場を再編すると予測しました。\n",
            "これは単に人間の職を代替するのではなく、AIと協力して新しい形の労働を生み出すことを意味します。\n",
            "データ分析、顧客サービス、ソフトウェア開発などの分野で人間を支援するデジタル従業員として機能するAIベースのエージェントの世界が広がるでしょう。\n",
            "これにより、AIを活用した創造的な作業や問題解決能力が新しい労働市場の中核となります。ジェンセン・ファン氏は、AIが人間の能力を増幅させ、技術と人間の共存を通じてより良い社会を築くと強調しました。\n",
            "\n",
            "ファン氏の基調講演は、AIが単なる技術進歩ではなく、社会や産業の構造を根本的に変革するイノベーションの中心にあることを強調しました。彼はAIと人間が共に未来を設計する可能性について語りました。今こそ、AIが切り開く新しい時代に備え、技術と人間の共存が生み出すイノベーションをCES 2025のスローガン「DIVE IN」に基づいて探求しましょう。Jensen Huang, the founder of NVIDIA, delivered the keynote address at the opening of CES 2025.\n",
            "The venue was filled with excitement, anticipation, and curiosity. His confident and charismatic speech captivated the audience in an instant.\n",
            "Along with the speech, I analyzed the key themes presented in his keynote as a judge for the CES 2025 Innovation Awards.\n",
            "Huang's keynote can be summarized as advancements in AI and computing, industrial AI and digital twins, autonomous driving and synthetic data, humanoid and general robotics, and AI agents.\n",
            "\n",
            "Innovations in AI and Computing, Opening a New Future\n",
            "Jensen Huang diagnosed that GPUs are driving a paradigm shift in modern computing.\n",
            "He explained the transition from CPU-based computing to GPU-based accelerated computing, noting that AI is becoming the central axis of computing infrastructure.\n",
            "He also emphasized that NVIDIA’s CUDA (Compute Unified Device Architecture) enables complex AI algorithms to be efficiently processed through programmable GPUs, making a wide range of AI research and applications possible.\n",
            "Furthermore, AI is evolving to a new dimension by acquiring the ability to comprehensively understand and generate text, images, and speech.\n",
            "\n",
            "AI and Digital Twins, Leading Industrial Innovation\n",
            "Jensen Huang predicted that digital twins would connect AI with the physical world to drive industrial innovation.\n",
            "He explained that NVIDIA's Omniverse platform simulates physical environments digitally, and Cosmos combines AI with physical data to enhance simulations.\n",
            "Huang asserted that this enables the design of optimal processes in manufacturing, logistics, and energy industries, driving industrial innovation.\n",
            "Digital twins, as powerful tools capable of replicating and optimizing all physical environments digitally, will transform the future of manufacturing and logistics industries through AI evolution.\n",
            "\n",
            "AI Synthetic Data, Ushering in a New Era of Autonomous Driving Safety\n",
            "Jensen Huang particularly emphasized the importance of synthetic data in advancing autonomous driving technology.\n",
            "He noted that AI models for autonomous vehicles are trained with synthetic data, which supplements real-world data and enhances the reliability of the technology.\n",
            "Synthetic data generated through Omniverse and Cosmos allows various driving scenarios to be simulated, improving the accuracy of AI models and enhancing vehicle safety.\n",
            "\n",
            "AI and the Era of Coexistence with Humanoids\n",
            "Jensen Huang predicted that robotics, when combined with AI, will open a new era of collaboration between humans and robots.\n",
            "He particularly envisioned that advancements in humanoid and general robotics would complement human labor and create new possibilities.\n",
            "In the future, humanoid robots will mimic human movements and operate in various industrial fields. As they learn from vast synthetic data and real-world data, they will be able to perform increasingly complex tasks.\n",
            "Humanoid robots will go beyond merely replacing human labor and become tools that create new value through collaboration with humans. This is expected to accelerate changes in the manufacturing and service industries.\n",
            "\n",
            "AI, Creating a New Workforce\n",
            "Jensen Huang predicted that AI would create a new workforce and restructure the existing labor market.\n",
            "This does not simply mean replacing human jobs but signifies creating new forms of work through collaboration with AI.\n",
            "A world of AI-based agents will emerge, acting as digital employees that assist humans in fields like data analysis, customer service, and software development.\n",
            "This will make creative tasks and problem-solving abilities utilizing AI the core of the new labor market. Jensen Huang emphasized that AI amplifies human capabilities and will build a better society through the coexistence of technology and humanity.\n",
            "\n",
            "Huang’s keynote emphasized that AI is not just a technological advancement but a central force of innovation that fundamentally changes the structure of society and industries. He discussed the possibilities of designing the future collaboratively with AI and humanity. Now, let us prepare for the new era that AI will usher in and explore the innovations created by the coexistence of technology and humanity, as stated in the CES 2025 slogan, \"DIVE IN.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"OpenAI API Key : \")\n"
      ],
      "metadata": {
        "id": "0xpu6Ej2Qw51",
        "outputId": "0c2014ff-a725-4c21-9470-611efc647470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key : ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YROV1fZC9Vy",
        "outputId": "a0f82fd8-2a68-4ab8-d871-f4896a256c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu  ## FAISS cpu 버젼 설치\n"
      ],
      "metadata": {
        "id": "fByEacXG9PKt",
        "outputId": "3cf9f0f9-6038-448a-ff01-4ada73162c8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:   # FAISS 설치 확인\n",
        "    import faiss\n",
        "    print(\"FAISS successfully imported.\")\n",
        "except ImportError as e:\n",
        "    print(f\"FAISS import failed: {e}\")"
      ],
      "metadata": {
        "id": "x9IVvKZQ9WpG",
        "outputId": "f1acedf7-4db1-4c15-acbe-144fff38de24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS successfully imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v3w1yb1k1xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38ecc29-9c86-4aad-fd2a-a5584e1a7a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(docs) ==  1\n",
            "faissIndex ==  <langchain_community.vectorstores.faiss.FAISS object at 0x7f50614aec50>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dotenv\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "\n",
        "# loads .env file with your OPENAI_API_KEY\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "# Doc Info from 젠슨황의 CES 2025 기조연결\n",
        "\n",
        "# loader = TextLoader(\"ces2025_ko.txt\",encoding=\"CP949\")\n",
        "# loader = TextLoader(\"ces2025_ko.txt\",encoding=\"euc-kr\")\n",
        "loader = TextLoader(\"ces2025_ko.txt\",encoding=\"utf-8\")\n",
        "# loader = TextLoader(\"ces2025_en.txt\",encoding=\"utf-8\")\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(\"len(docs) == \", len(docs))\n",
        "\n",
        "faissIndex = FAISS.from_documents(docs, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY))\n",
        "print(\"faissIndex == \", faissIndex )\n",
        "# OpenAIEmbeddings()\n",
        "info_idx = \"faiss_ces2025_ko\" # 파일이름  txt\n",
        "#info_idx = \"faiss_ces2025_en\" # 파일이름  txt\n",
        "#info_idx = \"faiss_ces2025_jp\" # 파일이름  txt\n",
        "\n",
        "faissIndex.save_local(info_idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 연관 자료탐색\n",
        "# print(\"docs[0] == \", docs[0])\n",
        "\n",
        "# question = \"질문 1: 젠슨 황의 CES 2025 기조연설의 주요 주제는 무엇인가요?\"\n",
        "# question = \"질문 2: 디지털 트윈(Digital Twin)이 산업 혁신에 어떻게 기여한다고 설명되었나요? 한줄로 답해줘\"\n",
        "# question = \"질문 3: 젠슨 황은 AI가 새로운 노동 계층을 어떻게 창출한다고 전망했나요?\"\n",
        "# question = \"앞으로 ai에서 가장 중요한것은 무엇인가요?\"\n",
        "\n",
        "query = question\n",
        "retriever = faissIndex.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})\n",
        "relevant_docs =  retriever.get_relevant_documents(query)\n",
        "\n",
        "num_docs = len(relevant_docs)\n",
        "print(\"len(relevant_docs) == \", num_docs)\n",
        "for i in range(num_docs) :\n",
        " print(\"relevant_docs[\", i , \"] == \", relevant_docs[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "w24z4OW6iTnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8a8b4b-26f8-4102-e01b-5ee790b48da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(relevant_docs) ==  1\n",
            "relevant_docs[ 0 ] ==  page_content='젠슨 황 엔비디아 창업자가 CES 2025 개막 기조연설을 했다. 현장은 설렘과 기대감, 호기심으로 가득 찼다. 자신감과 카리스마 넘치는 연설은 순식간에 청중을 빨아들였다. \n",
            "연설과 함께 필자는 CES 2025 혁신상 심사위원으로서 그의 기조연설에 나타난 핵심 주제를 분석해봤다.황의 기조연설은 AI와 컴퓨팅 혁신, 산업 AI와 디지털 트윈, 자율주행과 합성 데이터, 휴머노이드 로봇과 일반 로봇공학, AI 에이전트로 요약됐다.\n",
            "◇ AI와 컴퓨팅의 혁신, 새로운 미래 연다\n",
            "젠슨 황은 GPU가 현대 컴퓨팅의 패러다임 전환을 이끌고 있다고 진단했다. 기존의 CPU 중심 컴퓨팅에서 GPU 기반 가속 컴퓨팅으로 이동하며, AI가 컴퓨팅 인프라의 중심축으로 자리 잡고 있다는 분석이다.\n",
            "그는 엔비디아의 쿠다(CUDA)는 프로그래밍 가능한 GPU를 통해 복잡한 AI 알고리즘을 효율적으로 처리할 수 있도록 함으로써 다양한 AI 연구와 응용을 가능하게 했다고 설명했다.\n",
            "또한 AI가 텍스트, 이미지, 음성 등을 종합적으로 이해하고 생성할 수 있는 능력을 가지면서 AI가 새로운 차원으로 진화하고 있다.\n",
            "◇ AI와 디지털 트윈, 산업혁신 이끈다\n",
            "젠슨 황은 디지털 트윈(Digital Twin)이 AI와 물리적 세계를 연결해 산업혁신을 일이킬 것이라고 전망했다. \n",
            "그는 엔비디아의 옴니버스(Omniverse) 플랫폼이 물리적 환경을 디지털로 시뮬레이션해주고 코스모스(Cosmos)가 AI와 물리적 데이터를 결합해 시뮬레이션을 고도화하는 역할을 한다고 설명했다. 황은 이를 통해 제조, 물류, 에너지 산업에서 최적의 프로세스를 설계해 산업을 혁신할 수 있다고 단언했다.\n",
            "디지털 트윈은 모든 물리적 환경을 디지털로 재현하고 최적화할 수 있는 강력한 도구로 AI의 진화는 제조와 물류 산업의 미래를 변화시킬 전망이다.\n",
            "◇ AI 합성 데이터, 자율주행 안전시대 연다 \n",
            "젠슨 황은 자율주행 기술의 발전에서 합성 데이터의 중요성을 특히 강조했다. 자율주행차의 AI 모델은 합성 데이터를 통해 훈련되며, 이 데이터는 실제 데이터를 보완해 기술의 신뢰성을 높이는 역할을 한다. \n",
            "옴니버스와 코스모스를 통해 생성된 합성 데이터는 다양한 주행 시나리오를 시뮬레이션해 AI 모델의 정확성을 높여 차량의 안정성을 향상시킬 수 있다.\n",
            "◇ AI, 휴머노이드 공존시대 연다\n",
            "젠슨 황은 로봇공학이 AI와 결합하며 인간과 협력하는 새로운 시대를 열 것이라고 전망했다. 특히, 휴머노이드 로봇과 일반 로봇의 발전은 인간의 노동을 보완하고 새로운 가능성을 창출할 것으로 내다봤다.\n",
            "장차 휴머노이드 로봇은 인간의 동작을 모방해 다양한 산업 영역에서 활동하게 되며 방대한 합성 데이터와 현실 세계의 데이터를 로봇이 학습해 갈수록 복잡한 작업을 수행할 수 있게 된다.\n",
            "휴머노이드 로봇이 단순한 노동 대체를 넘어, 인간과의 협력을 통해 새로운 가치를 창출할 수 있는 도구가 된다. 이는 제조업과 서비스 산업의 변화를 촉진할 전망이다. \n",
            "◇ AI, 새로운 노동 계층을 창출하다\n",
            "젠슨 황은 AI가 새로운 노동 계층을 창출해 기존의 노동 시장을 재편할 것이라고 전망했다. 이는 단순히 인간의 일자리를 대체하는 것이 아니라, AI와 협력해 새로운 형태의 노동을 만들어내는 것을 의미한다.\n",
            "데이터 분석, 고객 서비스, 소프트웨어 개발 등에서 인간을 돕는 디지털 직원으로 역할을 하는 AI 기반 에이전트 세상이 열린다. 이로 인해 AI를 활용한 창의적 작업과 문제 해결 능력은 새로운 노동 시장의 핵심이 된다. 젠슨 황은 AI가 인간의 역량을 증폭시키며, 기술과 인간의 공존을 통해 더 나은 사회를 만들 것이라고 강조했다.\n",
            "젠슨 황은 기조연설을 통해 AI가 단순히 기술의 진보가 아니라, 사회와 산업의 구조를 근본적으로 변화시키는 혁신의 중심에 있음을 강조했다. AI와 인간이 함께 설계하는 미래의 가능성을 이야기한 것이다. 이제 우리는 AI가 열어갈 새로운 시대를 준비하며, 기술과 인간의 공존이 만들어낼 혁신을 CES 2025 슬로건대로 ‘탐구(DIVE IN)’하자.' metadata={'source': 'ces2025_ko.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFuhleVjJxBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aaa#\n"
      ],
      "metadata": {
        "id": "QBQAl74-joUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, dotenv\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "chatbot = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(\n",
        "        openai_api_key=OPENAI_API_KEY,\n",
        "        temperature=0,\n",
        "        # model_name=\"gpt-4o\",\n",
        "        model_name=\"gpt-4o-mini\",\n",
        "        # model_name=\"gpt-3.5-turbo\",\n",
        "        max_tokens=2000,  #max_tokens=50\n",
        "        streaming=True,\n",
        "    ),\n",
        "    #     llm=OpenAI(\n",
        "    #     openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    #     temperature=0, model_name=\"text-davinci-003\", max_tokens=1000  #max_tokens=50\n",
        "    # ),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    # retriever=FAISS.load_local(info_idx, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        "    #                            allow_dangerous_deserialization=True).as_retriever(search_type=\"similarity\", search_kwargs={\"k\":1},)\n",
        ")\n",
        "\n",
        "\n",
        "# template = \"\"\"\n",
        "# 충청도 사투리로  상세하게 답을 해줘. {query}?\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "# template = \"\"\"\n",
        "# respond as succinctly as possible like the following :\n",
        "# 1. xxx\n",
        "# 2. xxx\n",
        "# ...\n",
        "# 10. xxx\n",
        "\n",
        "# {query}?\n",
        "# \"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "respond as thoroughly as possible. {query}?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# # 없는 정보를 사용하지 않도록 제한\n",
        "\n",
        "/\n",
        "\n",
        "# template = \"\"\"\n",
        "# {query}\n",
        "# 질문에 대해서 아래에 주어진 문맥을 바탕으로 제주도 사투리로 답을 해줘.\n",
        "# 문맥에 답이 없으면 '몰라용' 이라고 해줘.\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "# template = \"\"\"\n",
        "# {query}\n",
        "# 질문에 대해서 아래에 주어진 문맥을 바탕으로 북한 아나운서 스타일로 답을 해줘.\n",
        "# 문맥에 답이 없으면 '몰라용' 이라고 해줘.\n",
        "# \"\"\"\n",
        "\n",
        "# template = \"\"\"\n",
        "# {query}\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# template = \"\"\"\n",
        "# {query}\n",
        "\n",
        "# Answer in Korean.\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "Context = [{'role':'system','content':\"\"\" You’re a helpful assistant.\n",
        "Please answer in a lastly questioned language.\"\"\"}]\n",
        "# accumulate message\n",
        "# question = \"what is --v\"\n",
        "# print(chatbot.run(\n",
        "#     prompt.format(query=question)\n",
        "# ))\n",
        "# # --v is a parameter used to specify a specific model version in Midjourney's AI image generation tool."
      ],
      "metadata": {
        "id": "N7FAIwagn8Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#######\n",
        "# question = \"젠승황의 주요요지는?\"\n",
        "question = \"질문 1: 젠슨 황의 CES 2025 기조연설의 주요 주제는 무엇인가요??\"\n",
        "# question = \"what is autopilot?\"  # 오류도 발생\n",
        "# question = \"what is main issue of CEs 2025?\"            #\n",
        "# question = \"人工知能自律走行とは何ですか？?\"             #\n",
        "# question = \"what is AI Robot?\"\n",
        "# question = \"Quels sont les principaux thèmes abordés dans le discours de Jensen Huang à l'ouverture du CES 2025 ??\"            # 프랑스어질문 (젠슨 황이 CES 2025 개막 연설에서 다룬 주요 주제는 무엇인가요?)\n",
        "\n",
        "# question = \"Welche Rolle spielt die GPU-Technologie bei der Transformation moderner Computersysteme laut Jensen Huang? \"   #독일어  질문 : (젠슨 황에 따르면 GPU 기술이 현대 컴퓨팅 시스템의 전환에서 어떤 역할을 하나요?)\n",
        "# question = \"根据黄仁勋的演讲，数字孪生技术如何推动工业创新？\"           # 중국어 질문 (젠슨 황의 연설에 따르면 디지털 트윈 기술이 산업 혁신을 어떻게 촉진하나요?)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(chatbot.run(\n",
        "    prompt.format(query=question)\n",
        "))"
      ],
      "metadata": {
        "id": "84bo2y1GtFoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b24ede1-00a2-41f5-c6eb-100c0c64ecd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "젠슨 황의 CES 2025 기조연설의 주요 주제는 다음과 같이 요약될 수 있습니다:\n",
            "\n",
            "1. **AI와 컴퓨팅 혁신**: 젠슨 황은 GPU가 현대 컴퓨팅의 패러다임 전환을 이끌고 있으며, AI가 컴퓨팅 인프라의 중심축으로 자리 잡고 있다고 강조했습니다. 그는 엔비디아의 쿠다(CUDA) 기술을 통해 복잡한 AI 알고리즘을 효율적으로 처리할 수 있는 가능성을 설명했습니다.\n",
            "\n",
            "2. **AI와 디지털 트윈**: 디지털 트윈이 AI와 물리적 세계를 연결하여 산업 혁신을 이끌 것이라고 전망했습니다. 엔비디아의 옴니버스(Omniverse) 플랫폼이 물리적 환경을 디지털로 시뮬레이션하고, 코스모스(Cosmos)가 AI와 물리적 데이터를 결합해 시뮬레이션을 고도화하는 역할을 한다고 설명했습니다.\n",
            "\n",
            "3. **AI 합성 데이터와 자율주행**: 자율주행 기술의 발전에서 합성 데이터의 중요성을 강조하며, 합성 데이터가 AI 모델의 훈련에 기여하고 기술의 신뢰성을 높이는 역할을 한다고 언급했습니다.\n",
            "\n",
            "4. **AI와 휴머노이드 로봇**: 로봇공학이 AI와 결합하여 인간과 협력하는 새로운 시대를 열 것이라고 전망했습니다. 휴머노이드 로봇이 인간의 동작을 모방하고 다양한 산업에서 활동하게 될 것이라고 설명했습니다.\n",
            "\n",
            "5. **AI가 창출하는 새로운 노동 계층**: AI가 기존의 노동 시장을 재편하고 새로운 형태의 노동을 만들어낼 것이라고 강조했습니다. AI 기반 에이전트가 데이터 분석, 고객 서비스, 소프트웨어 개발 등에서 인간을 돕는 역할을 하게 될 것이라고 언급했습니다.\n",
            "\n",
            "이러한 주제들은 AI가 단순한 기술의 진보를 넘어 사회와 산업의 구조를 근본적으로 변화시키는 혁신의 중심에 있음을 강조하며, AI와 인간이 함께 설계하는 미래의 가능성을 제시하고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "GSBcwvk0t2VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BY2jQBsQ2Gqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}